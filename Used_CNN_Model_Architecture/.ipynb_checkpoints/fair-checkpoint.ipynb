{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb99d595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import random \n",
    "import cv2\n",
    "import imutils\n",
    "# import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.utils import np_utils\n",
    "# from keras.models import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "# \n",
    "from keras import optimizers\n",
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "from keras import backend as K\n",
    "# from keras.layers import Dense, Activation, Flatten, Dense,MaxPooling2D, Dropout\n",
    "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.layers import Conv2D,  BatchNormalization\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f93349",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333333\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_IMAGE_SIZE = tuple((224, 224))\n",
    "\n",
    "# Number of images used to train the model\n",
    "N_IMAGES = 4787\n",
    "\n",
    "# Path to the dataset folder\n",
    "root_dir = 'D:\\\\datasets\\\\Dataset\\\\Brain_Tumor_Data_Set'\n",
    "\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "test_dir = os.path.join(root_dir, 'test')\n",
    "\n",
    "print(\"333333\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde1d391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, DEFAULT_IMAGE_SIZE)   \n",
    "            return img_to_array(image)\n",
    "        else:\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a935de34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Processing Brain_Tumour_L1 ...\n",
      "[INFO] Processing Brain_Tumour_L2 ...\n",
      "[INFO] Processing Brain_Tumour_L3 ...\n",
      "[INFO] Processing Brain_Tumour_L4 ...\n",
      "[INFO] Processing Healthy ...\n",
      "[INFO] Image loading completed\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "    \n",
    "image_list, label_list = [], []\n",
    "    \n",
    "try:\n",
    "    print(\"[INFO] Loading images ...\")\n",
    "    brain_disease_folder_list = listdir(train_dir)\n",
    "\n",
    "    for brain_disease_folder in brain_disease_folder_list:\n",
    "        print(f\"[INFO] Processing {brain_disease_folder} ...\")\n",
    "        brain_disease_image_list = listdir(f\"{train_dir}/{brain_disease_folder}/\")\n",
    "\n",
    "        for image in brain_disease_image_list[:N_IMAGES]:\n",
    "            image_directory = f\"{train_dir}/{brain_disease_folder}/{image}\"\n",
    "            if image_directory.endswith(\".png\")==True or image_directory.endswith(\".jpg\")==True:\n",
    "                image_list.append(convert_image_to_array(image_directory))\n",
    "                label_list.append(brain_disease_folder)\n",
    "\n",
    "    print(\"[INFO] Image loading completed\")  \n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")\n",
    "\n",
    "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a20f76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 4775\n",
      "Total number of classes:  5\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "image_len = len(image_list)\n",
    "print(f\"Total number of images: {image_len}\")\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "image_labels = label_binarizer.fit_transform(label_list)\n",
    "\n",
    "pickle.dump(label_binarizer,open('brain_disease_label_transform.pkl', 'wb'))\n",
    "n_classes = len(label_binarizer.classes_)\n",
    "\n",
    "print(\"Total number of classes: \", n_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "867b4ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Splitting data to train and test...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 86528)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               44302848  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 1285      \n",
      "=================================================================\n",
      "Total params: 44,528,709\n",
      "Trainable params: 44,528,709\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[INFO] Training network...\n",
      "Epoch 1/10\n",
      "120/120 [==============================] - ETA: 0s - loss: 1.2885 - accuracy: 0.5060\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.56754, saving model to ctscan.hdf5\n",
      "120/120 [==============================] - 357s 3s/step - loss: 1.2885 - accuracy: 0.5060 - val_loss: 1.0533 - val_accuracy: 0.5675\n",
      "Epoch 2/10\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.9403 - accuracy: 0.6387\n",
      "Epoch 00002: val_accuracy improved from 0.56754 to 0.66597, saving model to ctscan.hdf5\n",
      "120/120 [==============================] - 355s 3s/step - loss: 0.9403 - accuracy: 0.6387 - val_loss: 0.8496 - val_accuracy: 0.6660\n",
      "Epoch 3/10\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.7196 - accuracy: 0.7207\n",
      "Epoch 00003: val_accuracy improved from 0.66597 to 0.74764, saving model to ctscan.hdf5\n",
      "120/120 [==============================] - 363s 3s/step - loss: 0.7196 - accuracy: 0.7207 - val_loss: 0.6645 - val_accuracy: 0.7476\n",
      "Epoch 4/10\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.5736 - accuracy: 0.7751\n",
      "Epoch 00004: val_accuracy improved from 0.74764 to 0.75183, saving model to ctscan.hdf5\n",
      "120/120 [==============================] - 357s 3s/step - loss: 0.5736 - accuracy: 0.7751 - val_loss: 0.6267 - val_accuracy: 0.7518\n",
      "Epoch 5/10\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.4491 - accuracy: 0.8314\n",
      "Epoch 00005: val_accuracy improved from 0.75183 to 0.76754, saving model to ctscan.hdf5\n",
      "120/120 [==============================] - 386s 3s/step - loss: 0.4491 - accuracy: 0.8314 - val_loss: 0.5724 - val_accuracy: 0.7675\n",
      "Epoch 6/10\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.3697 - accuracy: 0.8565\n",
      "Epoch 00006: val_accuracy improved from 0.76754 to 0.78743, saving model to ctscan.hdf5\n",
      "120/120 [==============================] - 427s 4s/step - loss: 0.3697 - accuracy: 0.8565 - val_loss: 0.5569 - val_accuracy: 0.7874\n",
      "Epoch 7/10\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.3106 - accuracy: 0.8840\n",
      "Epoch 00007: val_accuracy did not improve from 0.78743\n",
      "120/120 [==============================] - 404s 3s/step - loss: 0.3106 - accuracy: 0.8840 - val_loss: 0.5878 - val_accuracy: 0.7749\n",
      "Epoch 8/10\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.2522 - accuracy: 0.9042\n",
      "Epoch 00008: val_accuracy improved from 0.78743 to 0.78953, saving model to ctscan.hdf5\n",
      "120/120 [==============================] - 447s 4s/step - loss: 0.2522 - accuracy: 0.9042 - val_loss: 0.6763 - val_accuracy: 0.7895\n",
      "Epoch 9/10\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.2306 - accuracy: 0.9160\n",
      "Epoch 00009: val_accuracy did not improve from 0.78953\n",
      "120/120 [==============================] - 413s 3s/step - loss: 0.2306 - accuracy: 0.9160 - val_loss: 0.6257 - val_accuracy: 0.7822\n",
      "Epoch 10/10\n",
      "120/120 [==============================] - ETA: 0s - loss: 0.2017 - accuracy: 0.9264\n",
      "Epoch 00010: val_accuracy did not improve from 0.78953\n",
      "120/120 [==============================] - 347s 3s/step - loss: 0.2017 - accuracy: 0.9264 - val_loss: 0.6417 - val_accuracy: 0.7885\n",
      "[INFO] Saving model...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "# checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
    "\n",
    "augment = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "                             height_shift_range=0.1, shear_range=0.2, \n",
    "                             zoom_range=0.2, horizontal_flip=True, \n",
    "                             fill_mode=\"nearest\")\n",
    "\n",
    "print(\"[INFO] Splitting data to train and test...\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) \n",
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "STEPS = 138\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 32\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "DEPTH = 3\n",
    "\n",
    "from tensorflow.keras.layers import Input, ZeroPadding2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 5 \n",
    "\n",
    "# # Perform one-hot encoding on the labels\n",
    "# y_train_encoded = to_categorical(y_train, num_classes)\n",
    "# y_test_encoded = to_categorical(y_test, num_classes)\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "# num_classes = 4\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flattening layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Assuming num_classes is the number of classes for tumor severity levels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inputShape = (HEIGHT, WIDTH, DEPTH)\n",
    "chanDim = -1\n",
    "\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    inputShape = (DEPTH, HEIGHT, WIDTH)\n",
    "    chanDim = 1\n",
    "\n",
    "\n",
    "# Initialize optimizer\n",
    "opt = Adam(lr=LR, decay=LR / EPOCHS)\n",
    "\n",
    "# Compile model\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "#  Compile the model with categorical cross-entropy loss and Adam optimizer\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Train model\n",
    "print(\"[INFO] Training network...\")\n",
    "# history = model.fit_generator(augment.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "#                               validation_data=(x_test, y_test),\n",
    "#                               steps_per_epoch=len(x_train) // BATCH_SIZE,\n",
    "#                               epochs=EPOCHS, \n",
    "#                               verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint('ctscan.hdf5', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 1)\n",
    "history = model.fit(x_train,y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data = (x_test, y_test),callbacks=[checkpoint])\n",
    "# Train the model\n",
    "# history = model.fit(x_train, y_train_encoded, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(x_test, y_test_encoded), callbacks=[checkpoint])\n",
    "\n",
    "\n",
    "# Dump pickle file of the model\n",
    "# model.save(\"ctscan1.hdf5\")\n",
    "print(\"[INFO] Saving model...\")\n",
    "# pickle.dump(model,open('ctscan.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27864562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Brain_Tumour_L2\n",
      "Brain_Tumour_L2\n",
      "Brain_Tumour_L2\n",
      "Brain_Tumour_L4\n",
      "Brain_Tumour_L4\n",
      "Brain_Tumour_L3\n",
      "Brain_Tumour_L3\n",
      "Brain_Tumour_L3\n",
      "Brain_Tumour_L3\n",
      "Brain_Tumour_L2\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Healthy\n",
      "Brain_Tumour_L4\n",
      "Brain_Tumour_L2\n",
      "Brain_Tumour_L4\n",
      "Brain_Tumour_L2\n",
      "Brain_Tumour_L3\n",
      "Brain_Tumour_L2\n",
      "Brain_Tumour_L2\n",
      "Brain_Tumour_L2\n"
     ]
    }
   ],
   "source": [
    "# li=['glioma','meningioma','notumor','pituitary']\n",
    "# li=['adenocarcinoma','Normal']\n",
    "li=['Brain_Tumour_L1','Brain_Tumour_L2','Brain_Tumour_L3','Brain_Tumour_L4','Healthy']\n",
    "import tensorflow\n",
    "from keras.preprocessing import image\n",
    "modelfile=\"ctscan.hdf5\"\n",
    "model = tensorflow.keras.models.load_model(modelfile)\n",
    "from os import listdir\n",
    "test_dir=\"D:\\\\datasets\\\\brain1\\\\Testing\\\\pituitary\\\\\"\n",
    "dest_dir=\"D:\\\\datasets\\\\brain1\\\\test_images\\\\pituitary\\\\\"\n",
    "files = listdir(test_dir)\n",
    "import shutil\n",
    "\n",
    "\n",
    "for f in files:\n",
    "    filename=test_dir+f\n",
    "    dest=dest_dir+f\n",
    "    new_img = image.load_img(filename, target_size=(224, 224))\n",
    "    img = image.img_to_array(new_img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img / 255\n",
    "    pred = model.predict(img)\n",
    "#     fnm = filename\n",
    "    print(filename)\n",
    "#     print(pred)\n",
    "    d = pred.flatten()\n",
    "#     print(d)\n",
    "    j = d.max()\n",
    "#     print(j)\n",
    "    for index, item in enumerate(d):\n",
    "        if item == j:\n",
    "            class_name = li[index]\n",
    "            break\n",
    "    print(class_name)\n",
    "#     if class_name=='Brain_Tumor':\n",
    "#         dest=dest_dir+\"\\\\\"+f\n",
    "#         shutil.copy(filename, dest)\n",
    "#     elif class_name=='large_cell_carcinoma_left.hilum':\n",
    "#         dest=dest_dir+\"large.cell.carcinoma\\\\\"+f\n",
    "# #         ok_adenocarcinoma\\\\\n",
    "# #         shutil.copy(filename, dest)\n",
    "#     elif class_name=='normal':\n",
    "#         dest=dest_dir+\"normal\\\\\"+f\n",
    "# #         ok_adenocarcinoma\\\\\n",
    "# #         shutil.copy(filename, dest)\n",
    "#     elif class_name=='squamous_cell_carcinoma_left_hilum':\n",
    "#         dest=dest_dir+\"squamous.cell.carcinoma\\\\\"+f\n",
    "# #         ok_adenocarcinoma\\\\\n",
    "# #         shutil.copy(filename, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f94ca3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain_Tumor\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from keras.preprocessing import image\n",
    "modelfile=\"ctscan.hdf5\"\n",
    "model = tensorflow.keras.models.load_model(modelfile)\n",
    "def predict(fname):\n",
    "    li=['Brain_Tumor','Healthy']\n",
    "    filename=fname\n",
    "    dest=dest_dir+f\n",
    "    new_img = image.load_img(filename, target_size=(224, 224))\n",
    "    img = image.img_to_array(new_img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img / 255\n",
    "    pred = model.predict(img)\n",
    "#     print(pred)\n",
    "    d = pred.flatten()\n",
    "#     print(d)\n",
    "    j = d.max()\n",
    "#     print(j)\n",
    "    for index, item in enumerate(d):\n",
    "        if item == j:\n",
    "            class_name = li[index]\n",
    "    print(class_name)\n",
    "\n",
    "    \n",
    "predict('D:\\\\datasets\\\\brain1\\\\Testing\\\\pituitary\\\\Y4.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ce1efc-772e-493d-8109-bb7ed1ab3b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
