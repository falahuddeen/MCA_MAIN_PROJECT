{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import random \n",
    "import cv2\n",
    "import imutils\n",
    "# import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.utils import np_utils\n",
    "# from keras.models import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "# \n",
    "from keras import optimizers\n",
    "# from sklearn.preprocessing import LabelBinarizer\n",
    "from keras import backend as K\n",
    "# from keras.layers import Dense, Activation, Flatten, Dense,MaxPooling2D, Dropout\n",
    "# from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.layers import Conv2D,  BatchNormalization\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333333\n"
     ]
    }
   ],
   "source": [
    "DEFAULT_IMAGE_SIZE = tuple((224, 224))\n",
    "\n",
    "# Number of images used to train the model\n",
    "N_IMAGES = 9658\n",
    "\n",
    "# Path to the dataset folder\n",
    "root_dir = 'C:\\\\Users\\\\cnet\\\\Downloads\\\\For_MRI\\\\dataset\\\\mri_identify'\n",
    "\n",
    "train_dir = os.path.join(root_dir, 'train')\n",
    "test_dir = os.path.join(root_dir, 'test')\n",
    "\n",
    "print(\"333333\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array\n",
    "def convert_image_to_array(image_dir):\n",
    "    try:\n",
    "        image = cv2.imread(image_dir)\n",
    "        if image is not None:\n",
    "            image = cv2.resize(image, DEFAULT_IMAGE_SIZE)   \n",
    "            return img_to_array(image)\n",
    "        else:\n",
    "            return np.array([])\n",
    "    except Exception as e:\n",
    "        print(f\"Error : {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading images ...\n",
      "[INFO] Processing mri ...\n",
      "[INFO] Processing non_mri ...\n",
      "[INFO] Image loading completed\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "    \n",
    "image_list, label_list = [], []\n",
    "    \n",
    "try:\n",
    "    print(\"[INFO] Loading images ...\")\n",
    "    brain_disease_folder_list = listdir(train_dir)\n",
    "\n",
    "    for brain_disease_folder in brain_disease_folder_list:\n",
    "        print(f\"[INFO] Processing {brain_disease_folder} ...\")\n",
    "        brain_disease_image_list = listdir(f\"{train_dir}/{brain_disease_folder}/\")\n",
    "\n",
    "        for image in brain_disease_image_list[:N_IMAGES]:\n",
    "            image_directory = f\"{train_dir}/{brain_disease_folder}/{image}\"\n",
    "            if image_directory.endswith(\".png\")==True or image_directory.endswith(\".jpg\")==True:\n",
    "                image_list.append(convert_image_to_array(image_directory))\n",
    "                label_list.append(brain_disease_folder)\n",
    "\n",
    "    print(\"[INFO] Image loading completed\")  \n",
    "except Exception as e:\n",
    "    print(f\"Error : {e}\")\n",
    "\n",
    "np_image_list = np.array(image_list, dtype=np.float16) / 225.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 9351\n",
      "Total number of classes:  2\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "image_len = len(image_list)\n",
    "print(f\"Total number of images: {image_len}\")\n",
    "\n",
    "label_binarizer = LabelBinarizer()\n",
    "image_labels = label_binarizer.fit_transform(label_list)\n",
    "\n",
    "pickle.dump(label_binarizer,open('brain_disease_label_transform.pkl', 'wb'))\n",
    "n_classes = len(label_binarizer.classes_)\n",
    "\n",
    "print(\"Total number of classes: \", n_classes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Splitting data to train and test...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 109, 109, 64)      18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 52, 52, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 26, 26, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 86528)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               44302848  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 44,527,938\n",
      "Trainable params: 44,527,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "[INFO] Training network...\n",
      "Epoch 1/10\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9675\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.99679, saving model to ctscan.hdf5\n",
      "234/234 [==============================] - 849s 4s/step - loss: 0.0998 - accuracy: 0.9675 - val_loss: 0.0208 - val_accuracy: 0.9968\n",
      "Epoch 2/10\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9951\n",
      "Epoch 00002: val_accuracy improved from 0.99679 to 0.99733, saving model to ctscan.hdf5\n",
      "234/234 [==============================] - 834s 4s/step - loss: 0.0178 - accuracy: 0.9951 - val_loss: 0.0195 - val_accuracy: 0.9973\n",
      "Epoch 3/10\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9977\n",
      "Epoch 00003: val_accuracy improved from 0.99733 to 0.99893, saving model to ctscan.hdf5\n",
      "234/234 [==============================] - 827s 4s/step - loss: 0.0152 - accuracy: 0.9977 - val_loss: 0.0137 - val_accuracy: 0.9989\n",
      "Epoch 4/10\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9960\n",
      "Epoch 00004: val_accuracy did not improve from 0.99893\n",
      "234/234 [==============================] - 891s 4s/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0309 - val_accuracy: 0.9957\n",
      "Epoch 5/10\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.0203 - accuracy: 0.9957\n",
      "Epoch 00005: val_accuracy did not improve from 0.99893\n",
      "234/234 [==============================] - 926s 4s/step - loss: 0.0203 - accuracy: 0.9957 - val_loss: 0.0207 - val_accuracy: 0.9947\n",
      "Epoch 6/10\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9969\n",
      "Epoch 00006: val_accuracy did not improve from 0.99893\n",
      "234/234 [==============================] - 888s 4s/step - loss: 0.0120 - accuracy: 0.9969 - val_loss: 0.0255 - val_accuracy: 0.9984\n",
      "Epoch 7/10\n",
      "234/234 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9989\n",
      "Epoch 00007: val_accuracy did not improve from 0.99893\n",
      "234/234 [==============================] - 1145s 5s/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0214 - val_accuracy: 0.9963\n",
      "Epoch 8/10\n",
      "234/234 [==============================] - ETA: 0s - loss: 8.7202e-04 - accuracy: 0.9997\n",
      "Epoch 00008: val_accuracy did not improve from 0.99893\n",
      "234/234 [==============================] - 1131s 5s/step - loss: 8.7202e-04 - accuracy: 0.9997 - val_loss: 0.0293 - val_accuracy: 0.9989\n",
      "Epoch 9/10\n",
      "234/234 [==============================] - ETA: 0s - loss: 7.5293e-04 - accuracy: 0.9999\n",
      "Epoch 00009: val_accuracy did not improve from 0.99893\n",
      "234/234 [==============================] - 1160s 5s/step - loss: 7.5293e-04 - accuracy: 0.9999 - val_loss: 0.0509 - val_accuracy: 0.9989\n",
      "Epoch 10/10\n",
      "234/234 [==============================] - ETA: 0s - loss: 5.5619e-05 - accuracy: 1.0000\n",
      "Epoch 00010: val_accuracy did not improve from 0.99893\n",
      "234/234 [==============================] - 1147s 5s/step - loss: 5.5619e-05 - accuracy: 1.0000 - val_loss: 0.0452 - val_accuracy: 0.9989\n",
      "[INFO] Saving model...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "# checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
    "\n",
    "augment = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
    "                             height_shift_range=0.1, shear_range=0.2, \n",
    "                             zoom_range=0.2, horizontal_flip=True, \n",
    "                             fill_mode=\"nearest\")\n",
    "\n",
    "print(\"[INFO] Splitting data to train and test...\")\n",
    "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) \n",
    "\n",
    "\n",
    "EPOCHS = 10\n",
    "STEPS = 292\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 32\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "DEPTH = 3\n",
    "\n",
    "from tensorflow.keras.layers import Input, ZeroPadding2D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "# Number of classes\n",
    "num_classes = 2  # assuming 4 classes: glioma, meningioma, notumor, pituitary\n",
    "\n",
    "# # Perform one-hot encoding on the labels\n",
    "y_train_encoded = to_categorical(y_train, num_classes)\n",
    "y_test_encoded = to_categorical(y_test, num_classes)\n",
    "\n",
    "input_shape = (224, 224, 3)\n",
    "# num_classes = 4\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional layers\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flattening layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Fully connected layers\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Assuming num_classes is the number of classes for tumor severity levels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inputShape = (HEIGHT, WIDTH, DEPTH)\n",
    "chanDim = -1\n",
    "\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    inputShape = (DEPTH, HEIGHT, WIDTH)\n",
    "    chanDim = 1\n",
    "\n",
    "\n",
    "# Initialize optimizer\n",
    "opt = Adam(lr=LR, decay=LR / EPOCHS)\n",
    "\n",
    "# Compile model\n",
    "# model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "#  Compile the model with categorical cross-entropy loss and Adam optimizer\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# Train model\n",
    "print(\"[INFO] Training network...\")\n",
    "# history = model.fit_generator(augment.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
    "#                               validation_data=(x_test, y_test),\n",
    "#                               steps_per_epoch=len(x_train) // BATCH_SIZE,\n",
    "#                               epochs=EPOCHS, \n",
    "#                               verbose=1)\n",
    "\n",
    "checkpoint = ModelCheckpoint('ctscan.hdf5', monitor= 'val_accuracy', mode= 'max', save_best_only = True, verbose= 1)\n",
    "# history = model.fit(x_train,y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data = (x_test, y_test),callbacks=[checkpoint])\n",
    "# Train the model\n",
    "history = model.fit(x_train, y_train_encoded, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(x_test, y_test_encoded), callbacks=[checkpoint])\n",
    "\n",
    "\n",
    "# Dump pickle file of the model\n",
    "# model.save(\"ctscan1.hdf5\")\n",
    "print(\"[INFO] Saving model...\")\n",
    "# pickle.dump(model,open('ctscan.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\1.jpg\n",
      "non_mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\2.jpg\n",
      "non_mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\3-male.jpg\n",
      "non_mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\4-female.jpg\n",
      "non_mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\5-male.jpg\n",
      "non_mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\6-female.jpg\n",
      "non_mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\7-female.jpg\n",
      "non_mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\8-male.jpg\n",
      "non_mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\9-male.jpg\n",
      "non_mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c-1.jpg\n",
      "non_mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c-2.png\n",
      "non_mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c-3.png\n",
      "non_mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c-4.jpg\n",
      "non_mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c-5.jpg\n",
      "non_mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c-6.png\n",
      "non_mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c10-1.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c12.1.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c14.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c16.3.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c18.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c2-4.png\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c20.1.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c22.1.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c24.1.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c26.1.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c28.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c30.3.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c32.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c35.3.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c37.3.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c39.3.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c4-2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c41.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c43.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c45.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c47.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c49.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c51.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c53.1.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c55.1.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c56.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c57.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c58.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c59.1.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c6-1.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c61.1.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c63.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c65.3.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c67.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c69.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c71.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c73.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c75.2.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c77.3.jpg\n",
      "mri\n",
      "C:\\Users\\cnet\\Downloads\\For_MRI\\testing\\c8-2.jpg\n",
      "mri\n"
     ]
    }
   ],
   "source": [
    "# li=['glioma','meningioma','notumor','pituitary']\n",
    "# li=['adenocarcinoma','Normal']\n",
    "li=['mri','non_mri']\n",
    "import tensorflow\n",
    "from keras.preprocessing import image\n",
    "modelfile=\"ctscan.hdf5\"\n",
    "model = tensorflow.keras.models.load_model(modelfile)\n",
    "from os import listdir\n",
    "test_dir=\"C:\\\\Users\\\\cnet\\\\Downloads\\\\For_MRI\\\\testing\\\\\"\n",
    "dest_dir=\"D:\\\\datasets\\\\brain1\\\\test_images\\\\pituitary\\\\\"\n",
    "files = listdir(test_dir)\n",
    "import shutil\n",
    "for f in files:\n",
    "    filename=test_dir+f\n",
    "    dest=dest_dir+f\n",
    "    new_img = image.load_img(filename, target_size=(224, 224))\n",
    "    img = image.img_to_array(new_img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img / 255\n",
    "    pred = model.predict(img)\n",
    "\n",
    "    print(filename)\n",
    "    d = pred.flatten()\n",
    "#     print(d)\n",
    "    j = d.max()\n",
    "#     print(j)\n",
    "    for index, item in enumerate(d):\n",
    "        if item == j:\n",
    "            class_name = li[index]\n",
    "            break\n",
    "    print(class_name)\n",
    "    \n",
    "#     elif class_name=='large_cell_carcinoma_left.hilum':\n",
    "#         dest=dest_dir+\"large.cell.carcinoma\\\\\"+f\n",
    "# #         ok_adenocarcinoma\\\\\n",
    "# #         shutil.copy(filename, dest)\n",
    "#     elif class_name=='normal':\n",
    "#         dest=dest_dir+\"normal\\\\\"+f\n",
    "# #         ok_adenocarcinoma\\\\\n",
    "# #         shutil.copy(filename, dest)\n",
    "#     elif class_name=='squamous_cell_carcinoma_left_hilum':\n",
    "#         dest=dest_dir+\"squamous.cell.carcinoma\\\\\"+f\n",
    "# #         ok_adenocarcinoma\\\\\n",
    "# #         shutil.copy(filename, dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "from keras.preprocessing import image\n",
    "modelfile=\"ctscan.hdf5\"\n",
    "model = tensorflow.keras.models.load_model(modelfile)\n",
    "def predict(fname):\n",
    "    li=['Brain_Tumor','Healthy']\n",
    "    filename=fname\n",
    "    dest=dest_dir+f\n",
    "    new_img = image.load_img(filename, target_size=(224, 224))\n",
    "    img = image.img_to_array(new_img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = img / 255\n",
    "    pred = model.predict(img)\n",
    "    d = pred.flatten()\n",
    "    j = d.max()\n",
    "    for index, item in enumerate(d):\n",
    "        if item == j:\n",
    "            class_name = li[index]\n",
    "    print(class_name)\n",
    "\n",
    "    \n",
    "predict('D:\\\\datasets\\\\brain1\\\\Testing\\\\pituitary\\\\N3.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
